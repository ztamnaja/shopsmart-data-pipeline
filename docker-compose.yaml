# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

---
version: "3.8"

x-airflow-common: &airflow-common
  image: apache/airflow:latest
  environment: &airflow-common-env
    LOAD_EX: n
    EXECUTOR: Local
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:${AIRFLOW_DB_PASSWORD}@postgres/airflow # for airflow logs
    AIRFLOW_CONN_DESTINATION_POSTGRES: postgres://${DESTINATION_DB_USER}:${DESTINATION_DB_PASSWORD}@${DESTINATION_DB_HOST}:${DESTINATION_DB_PORT}/${DESTINATION_DB_NAME} # for processed data
    AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME: ${AIRFLOW_DEFAULT_WEBSERVER_USER}
    AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD: ${AIRFLOW_DEFAULT_WEBSERVER_PASSWORD}
    AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_DEFAULT_WEBSERVER_USER}
    AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_DEFAULT_WEBSERVER_PASSWORD}
    AIRFLOW__WEBSERVER__SECRET_KEY: secret
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    # _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-r requirements.txt} # work in test env

  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./raw_data:/opt/airflow/raw_data
    - ./processed_data:/opt/airflow/processed_data
    - ./connections.json:/opt/airflow/connections.json
  user: airflow
  depends_on:
    - postgres

services:
  destination_db:
    image: postgres:15.7
    ports:
      - "5434:5432"
    networks:
      - backend
    environment:
      POSTGRES_DB: ${DESTINATION_DB_NAME}
      POSTGRES_USER: ${DESTINATION_DB_USER}
      POSTGRES_PASSWORD: ${DESTINATION_DB_PASSWORD}
    volumes:
      - ./destination_db_init:/docker-entrypoint-initdb.d

  postgres:
    image: postgres:15.7
    networks:
      - backend
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=${AIRFLOW_DB_PASSWORD}
      - POSTGRES_DB=airflow

  airflow-init:
    image: apache/airflow:latest
    depends_on:
      - postgres
    networks:
      - backend
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:${AIRFLOW_DB_PASSWORD}@postgres/airflow
    command: >
      bash -c "airflow db init && 
               airflow users create --username ${AIRFLOW_DEFAULT_WEBSERVER_USER} --password ${AIRFLOW_DEFAULT_WEBSERVER_PASSWORD} --firstname John --lastname Doe --role Admin --email admin@example.com"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    networks:
      - backend
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      <<: *airflow-common-env
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    networks:
      - backend
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    environment:
      <<: *airflow-common-env

networks:
  backend:
    driver: "bridge"

volumes:
  postgres-db:
